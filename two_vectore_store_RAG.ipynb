{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing required modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "%pip install --quiet --no-build-isolation --force-reinstall \\\n",
    "    \"boto3\" \\\n",
    "    \"awscli\" \\\n",
    "    \"botocore\" \\\n",
    "    \"faiss-cpu\" \\\n",
    "    \"langchain\" \\\n",
    "    \"pypdf\" \\\n",
    "    \"sqlalchemy\" \\\n",
    "    \"pickle5\" \\\n",
    "    \"transformers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to aws bedrock service & get a client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-west-2\n",
      "  Using role: arn:aws:iam::195364414018:role/Crossaccountbedrock ... successful!\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"arn:aws:iam::195364414018:role/Crossaccountbedrock\"  # E.g. \"arn:aws:...\"\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating object of embedding and llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "br_embeddings = BedrockEmbeddings(\n",
    "    model_id=\"amazon.titan-embed-text-v1\", \n",
    "    client=boto3_bedrock\n",
    ")\n",
    "\n",
    "br_llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v2\",\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs={\"temperature\":0.1}\n",
    ")\n",
    "\n",
    "is_login=True\n",
    "user=\"MV123456789\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load PDF files from dir and store in vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spliting the content with length 5757\n",
      "Spliting the content with length 4317\n",
      "Spliting the content with length 280\n",
      "Spliting the content with length 4045\n",
      "Spliting the content with length 4043\n",
      "Spliting the content with length 6742\n",
      "Spliting the content with length 3221\n",
      "Spliting the content with length 5830\n",
      "Spliting the content with length 5840\n",
      "Spliting the content with length 6663\n",
      "Spliting the content with length 3329\n",
      "Spliting the content with length 3385\n",
      "Spliting the content with length 4846\n",
      "Spliting the content with length 6515\n",
      "Spliting the content with length 6493\n",
      "Spliting the content with length 6994\n",
      "Spliting the content with length 7020\n",
      "Spliting the content with length 332\n",
      "Spliting the content with length 35\n",
      "Spliting the content with length 391\n",
      "Spliting the content with length 1473\n",
      "Spliting the content with length 2889\n",
      "Spliting the content with length 2218\n",
      "Spliting the content with length 2405\n",
      "Spliting the content with length 826\n",
      "Spliting the content with length 3436\n",
      "Spliting the content with length 2915\n",
      "Spliting the content with length 2503\n",
      "Spliting the content with length 2827\n",
      "Spliting the content with length 2400\n",
      "Spliting the content with length 1974\n",
      "Spliting the content with length 2018\n",
      "Spliting the content with length 821\n",
      "Spliting the content with length 3237\n",
      "Spliting the content with length 3214\n",
      "Spliting the content with length 899\n",
      "Spliting the content with length 2681\n",
      "Spliting the content with length 689\n",
      "Spliting the content with length 4511\n",
      "Spliting the content with length 333\n",
      "Spliting the content with length 4519\n",
      "Spliting the content with length 4547\n",
      "Spliting the content with length 4690\n",
      "Spliting the content with length 4698\n",
      "Spliting the content with length 4324\n",
      "Spliting the content with length 6781\n",
      "Spliting the content with length 2796\n",
      "Spliting the content with length 5476\n",
      "Spliting the content with length 3359\n",
      "Spliting the content with length 5885\n",
      "Spliting the content with length 2638\n",
      "Spliting the content with length 5007\n",
      "Spliting the content with length 3319\n",
      "Spliting the content with length 6072\n",
      "Spliting the content with length 2160\n",
      "Spliting the content with length 4067\n",
      "Spliting the content with length 2490\n",
      "Spliting the content with length 4546\n",
      "Spliting the content with length 2832\n",
      "Spliting the content with length 5572\n",
      "Spliting the content with length 2802\n",
      "Spliting the content with length 4847\n",
      "Spliting the content with length 2705\n",
      "Spliting the content with length 6204\n",
      "Spliting the content with length 2144\n",
      "Spliting the content with length 4628\n",
      "Spliting the content with length 2203\n",
      "Spliting the content with length 2817\n",
      "Spliting the content with length 2481\n",
      "Spliting the content with length 5245\n",
      "Spliting the content with length 3266\n",
      "Spliting the content with length 110\n",
      "Spliting the content with length 107\n",
      "Spliting the content with length 107\n",
      "Spliting the content with length 684\n",
      "Spliting the content with length 5486\n",
      "Spliting the content with length 6709\n",
      "Spliting the content with length 5362\n",
      "Spliting the content with length 3159\n",
      "pub_vs: number of elements in the index=521\n",
      "Spliting the content with length 2579\n",
      "Spliting the content with length 85\n",
      "Spliting the content with length 1269\n",
      "Spliting the content with length 3463\n",
      "Spliting the content with length 85\n",
      "Spliting the content with length 1295\n",
      "Spliting the content with length 85\n",
      "Spliting the content with length 2567\n",
      "Spliting the content with length 708\n",
      "Spliting the content with length 2789\n",
      "Spliting the content with length 2121\n",
      "Spliting the content with length 819\n",
      "Spliting the content with length 85\n",
      "Spliting the content with length 2850\n",
      "Spliting the content with length 2124\n",
      "Spliting the content with length 2851\n",
      "Spliting the content with length 2124\n",
      "pvt_vs: number of elements in the index=53\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"public\")\n",
    "pages = loader.load()\n",
    "\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 500\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, \n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function = len,\n",
    ")\n",
    "\n",
    "docs, metadata = [], []\n",
    "\n",
    "for i in range(len(pages)):\n",
    "    print(f\"Spliting the content with length\", len(pages[i].page_content))\n",
    "    splits = text_splitter.split_text(pages[i].page_content)\n",
    "    docs.extend(splits)\n",
    "    metadata.extend([{\"source\": pages[i].metadata[\"source\"]}] * len(splits))\n",
    "\n",
    "pub_vs = FAISS.from_texts(\n",
    "    docs,\n",
    "    br_embeddings,\n",
    "    metadatas=metadata,\n",
    ")\n",
    "\n",
    "print(f\"pub_vs: number of elements in the index={pub_vs.index.ntotal}\")\n",
    "\n",
    "loader = PyPDFLoader(\"private/policy_certifcate_multiple_vehicle.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "docs, metadata = [], []\n",
    "\n",
    "for i in range(len(pages)):\n",
    "    print(f\"Spliting the content with length\", len(pages[i].page_content))\n",
    "    splits = text_splitter.split_text(pages[i].page_content)\n",
    "    docs.extend(splits)\n",
    "    metadata.extend([{\"source\": pages[i].metadata[\"source\"]}] * len(splits))\n",
    "\n",
    "pvt_vs = FAISS.from_texts(\n",
    "    docs,\n",
    "    br_embeddings,\n",
    "    metadatas=metadata,\n",
    ")\n",
    "\n",
    "print(f\"pvt_vs: number of elements in the index={pvt_vs.index.ntotal}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save vector store for later use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# print(type(pub_vs))\n",
    "# with open(\"pub_vs.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(pub_vs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding index wapper to vector store for faster querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test run query in pub_vs_index:\n",
      " Based on the policy details provided, I do not see an explicit \"account name\" for the policy. The\n",
      "policy refers to a \"principal policyholder\" who entered into the insurance contract, and \"vehicle\n",
      "policyholders\" who are main users of insured vehicles. But there is no specific \"account name\"\n",
      "mentioned for the policy itself.\n",
      "Test run query in pvt_vs_index:\n",
      " Based on the context provided, the account name for the policy is TestTester. The relevant line\n",
      "states:\n",
      "\n",
      "Accountname TestTester\n",
      "\n",
      "So the account name is TestTester.\n"
     ]
    }
   ],
   "source": [
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "pub_vs_index = VectorStoreIndexWrapper(vectorstore=pub_vs)\n",
    "print(\"Test run query in pub_vs_index:\")\n",
    "print_ww(pub_vs_index.query(\"Account name of the policy?\", llm=br_llm))\n",
    "\n",
    "pvt_vs_index = VectorStoreIndexWrapper(vectorstore=pvt_vs)\n",
    "print(\"Test run query in pvt_vs_index:\")\n",
    "print_ww(pvt_vs_index.query(\"Account name of the policy?\", llm=br_llm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating a function to extract context from pub and pvt PDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pdf_context(query):\n",
    "    # TODO: is user login \n",
    "    print(\"Getting PDF context from pub_vs_index\")\n",
    "    pub_context=\"\"\n",
    "    for k, i in enumerate(pub_vs_index.vectorstore.similarity_search(query, k=1)):\n",
    "        # print(f\"{k+1}. From {i.metadata['source']}\\n\")\n",
    "        pub_context += f\"{k+1}. From {i.metadata['source']} document :\\n{i.page_content}\\n\"\n",
    "        # print(f\"Content \\n{i.page_content} \\n\")\n",
    "\n",
    "    print(\"Getting PDF context from pvt_vs_index\")\n",
    "    pvt_context = \"\"\n",
    "    for k, i in enumerate(pvt_vs_index.vectorstore.similarity_search(query, k=1)):\n",
    "        # print(f\"{k+1}. From {i.metadata['source']}\\n\")\n",
    "        pvt_context += f\"{k+1}. From {i.metadata['source']} document :\\n{i.page_content}\\n\"\n",
    "        # print(f\"Content \\n{i.page_content} \\n\")\n",
    "    return pub_context, pvt_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Chat History Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory, ConversationSummaryMemory # llm \n",
    "\n",
    "# store previous interactions using ConversationalBufferMemory and add custom prompts to the chat.\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    # llm=br_llm,\n",
    "    input_key=\"customer_query\",\n",
    "    memory_key=\"history\", \n",
    "    return_messages=False, \n",
    "    k=3,\n",
    "    ai_prefix=\"Assistant\",\n",
    "    human_prefix=\"Human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt template for chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_template = \"\"\"\n",
    "Human: If customer start the conversation to greet you at any time, please greet them according to the time of the day and don't refer to any documents also don't return source document name in the responce.\n",
    "\n",
    "Assistant: I will definetly greet the customer according to the time of the day and I won't refer to any documents also I won't return any source document name in the responce.\n",
    "\n",
    "{history}\n",
    "\n",
    "Human:\n",
    "Consider the following document: {pvt_context} Please identify the context most relevant to the question unless the question is a greeting \"{customer_query}\" and copy them out word-for-word. \n",
    "If there are no context in this document than refer to this document {pub_context} that seem relevant to this question and copy them out word-for-word. \n",
    "If you couldn't find any relevant context, please reply to customer politely that you don't know the answer to the question could they rephrase the question.\n",
    "Return the source document name of the context you choose to answer the question in below format:\n",
    "Referenced Documents : <document_name>\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(template=_template, input_variables=[\"customer_query\", \"pub_context\", \"pvt_context\", \"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# _template = \"\"\"\n",
    "# Human: If customer start the conversation to greet you at any time, please greet them according to the time of the day and don't refer to any documents also don't return source document name in the responce.\n",
    "\n",
    "# Assistant: Ok, I will definetly greet the customer according to the time of the day and I won't refer to any documents also I won't return any source document name in the responce.\n",
    "\n",
    "# Human: You are a Insurance Assistant for Aviva.\n",
    "\n",
    "# Assistant: Ok I am Insurance Assistant for Aviva.\n",
    "\n",
    "# Human: Your primary role to answer the customer question with the private context, public context and previous chat history.\n",
    "\n",
    "# Assistant: Yes, my primary task is to answer customer query politely.\n",
    "\n",
    "# {history}\n",
    "\n",
    "# Human:\n",
    "# Consider the following document: {pvt_context} Please identify the context most relevant to the question unless the question is a greeting \"{customer_query}\" and copy them out word-for-word. \n",
    "# If there are no context in this document than refer to this document {pub_context} that seem relevant to this question and copy them out word-for-word. \n",
    "# If you couldn't find any relevant context, please reply to customer politely that you don't know the answer to the question could they rephrase the question.\n",
    "# Return the source document name of the context you choose to answer the question in below format:\n",
    "# Referenced Documents : <document_name>\n",
    "\n",
    "# Assistant:\n",
    "# \"\"\"\n",
    "# PROMPT = PromptTemplate(template=_template, input_variables=[\"customer_query\", \"pub_context\", \"pvt_context\", \"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn verbose to true to see the full logs and documents\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "qa = LLMChain(\n",
    "    llm=br_llm, \n",
    "    verbose=False, \n",
    "    prompt=PROMPT,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "def ask_copilot(query):\n",
    "    pub_context, pvt_context = get_pdf_context(query)\n",
    "    result = qa.predict(customer_query=query, pvt_context=pvt_context, pub_context=pub_context)\n",
    "    print(f\"\\nCopilot : \\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting PDF context from pub_vs_index\n",
      "Getting PDF context from pvt_vs_index\n",
      "\n",
      "Copilot : \n",
      " Referenced Documents : private/policy_certifcate_multiple_vehicle.pdf\n",
      "\n",
      "Account name of the policy?\n",
      "TestTester\n"
     ]
    }
   ],
   "source": [
    "ask_copilot(\"Account name of the policy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting PDF context from pub_vs_index\n",
      "Getting PDF context from pvt_vs_index\n",
      "\n",
      "Copilot : \n",
      " Referenced Documents : private/policy_certifcate_multiple_vehicle.pdf\n",
      "\n",
      "The cancellation fees and charges are not specified in the given document. The document mentions the complaints procedure and compensation scheme arrangements but does not provide information on cancellation fees and charges.\n"
     ]
    }
   ],
   "source": [
    "ask_copilot(\"What will be my Cancellation fees and charges?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting PDF context from pub_vs_index\n",
      "Getting PDF context from pvt_vs_index\n",
      "\n",
      "Copilot : \n",
      " Referenced Documents : private/policy_certifcate_multiple_vehicle.pdf\n",
      "\n",
      "Following the complaints procedure does not affect your right to take legal action. Further details of our complaints procedure can be found in your insurance documents, or may be obtained from your usual Aviva UK Digital Limited contact.\n"
     ]
    }
   ],
   "source": [
    "ask_copilot(\"How my Personal Information will be processed?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
